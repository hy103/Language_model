{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"slauw87/bart_summarisation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Rose has a beautiful rose garden\"\n",
    "\n",
    "input_tokens = tokenizer(sentence, padding = False, truncation = False,\n",
    "                         max_length=len(sentence))\n",
    "print(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_tokens[\"input_ids\"]\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_matrix = torch.zeros(len(input_ids), len(input_ids))\n",
    "for row in range(len(input_ids)):\n",
    "    for col in range(len(input_ids)):\n",
    "        attention_matrix[row][col] = np.dot(input_ids[row], input_ids[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = torch.zeros(len(attention_matrix), len(attention_matrix))\n",
    "for i, row in enumerate(attention_matrix):\n",
    "    attention_weights[i] = torch.softmax(attention_matrix[i], dim =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.softmax(torch.tensor([0.0000e+00, 6.2200e+08, 8.4796e+05, 2.4940e+05, 6.7862e+07, 3.6363e+07,\n",
    "         1.4143e+08, 4.9880e+04]), dim =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[3], out[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.tensor([0.0000e+00, 6.2200e+08, 8.4796e+05, 2.4940e+05, 6.7862e+07, 3.6363e+07,\n",
    "         1.4143e+08, 4.9880e+04])\n",
    "sum =0\n",
    "for i in range(len(sample)):\n",
    "    sum += torch.exp(sample[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Your input tokens (as provided)\n",
    "input_tokens = {'input_ids': [0, 24940, 34, 10, 2721, 1458, 5671, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
    "input_ids = torch.tensor(input_tokens['input_ids'], dtype=torch.float32)\n",
    "\n",
    "# Create the attention matrix (dot product of input_ids with themselves)\n",
    "attention_matrix = torch.matmul(input_ids.unsqueeze(1), input_ids.unsqueeze(0))\n",
    "\n",
    "# Scale the dot product by the square root of the dimension of the token vectors (for numerical stability)\n",
    "d_k = input_ids.size(-1)  # Dimension of the token vectors\n",
    "scaling_factor = torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "scaled_attention_matrix = attention_matrix / scaling_factor\n",
    "\n",
    "# Apply softmax to get the attention weights\n",
    "attention_weights = torch.softmax(scaled_attention_matrix, dim=-1)\n",
    "\n",
    "print(\"Attention Weights:\")\n",
    "print(attention_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"slauw87/bart_summarisation\")\n",
    "model = AutoModel.from_pretrained(\"slauw87/bart_summarisation\")\n",
    "\n",
    "input_ids = tokenizer(sentence, return_tensors= \"pt\", padding=False, truncation= False, max_length = len(sentence))\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**input_tokens)\n",
    "    embeddings = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[0][0:5], embeddings[0][4:8], embeddings[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings\n",
    "query = embeddings\n",
    "key = embeddings\n",
    "value = embeddings\n",
    "\n",
    "attention_scores = torch.dot(query, torch.t(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.t(key).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"slauw87/bart_summarisation\")\n",
    "model = AutoModel.from_pretrained(\"slauw87/bart_summarisation\")\n",
    "\n",
    "sentence = \"Rose has a beautiful rose garden\"\n",
    "input_tokens = tokenizer(sentence, return_tensors=\"pt\", padding=False, truncation=False)\n",
    "\n",
    "# Get token embeddings from the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**input_tokens)\n",
    "    embeddings = outputs.last_hidden_state  # Shape: (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "# Self-attention: Query, Key, Value are projections of the embeddings\n",
    "query = embeddings\n",
    "key = embeddings\n",
    "value = embeddings\n",
    "\n",
    "# Attention matrix: Dot product between query and key (transposed)\n",
    "attention_scores = torch.matmul(query, key.transpose(-2, -1))  # Shape: (seq_len, seq_len)\n",
    "\n",
    "# Scale by sqrt(d_k) (dimensionality of the embeddings for numerical stability)\n",
    "d_k = query.size(-1)  # The hidden size\n",
    "scaling_factor = torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "attention_scores = attention_scores / scaling_factor\n",
    "\n",
    "# Apply softmax to get attention weights\n",
    "attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "\n",
    "# Multiply attention weights by value to get the weighted sum (context vector)\n",
    "context_vectors = torch.matmul(attention_weights, value)\n",
    "\n",
    "print(\"Attention Weights:\")\n",
    "print(attention_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rose_word = torch.tensor([4.9993e-01, 4.9993e-01, 3.7399e-05, 3.0580e-06, 1.2836e-05,\n",
    "          1.7711e-05, 2.4050e-05, 4.2371e-05])\n",
    "\n",
    "has_word = torch.tensor([3.2027e-07, 3.2027e-07, 9.9963e-01, 3.4351e-04, 1.1782e-05,\n",
    "          2.8456e-06, 3.1065e-06, 5.0539e-06])\n",
    "beautiful_word = torch.tensor([1.2540e-06, 1.2540e-06, 1.3442e-04, 1.3896e-02, 9.8284e-01,\n",
    "          2.9472e-03, 1.5741e-04, 1.9449e-05])\n",
    "rose_word = torch.tensor([1.4967e-05, 1.4967e-05, 2.8082e-04, 2.9105e-03, 2.5495e-02,\n",
    "          9.6744e-01, 3.7435e-03, 1.0216e-04])\n",
    "garden_word = torch.tensor([1.5248e-04, 1.5248e-04, 2.3000e-03, 2.1980e-03, 1.0216e-02,\n",
    "          2.8086e-02, 9.5621e-01, 6.9020e-04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = torch.dot(Rose_word, has_word)\n",
    "print(f\"Sim b/w Rose_word, has_word : {s1}\")\n",
    "s2 = torch.dot(Rose_word, beautiful_word)\n",
    "print(f\"Sim b/w Rose_word, beautiful_word : {s2}\")\n",
    "s3 = torch.dot(Rose_word, rose_word)\n",
    "print(f\"Sim b/w Rose_word, rose_word : {s3}\")\n",
    "s4 = torch.dot(Rose_word, garden_word)\n",
    "print(f\"Sim b/w Rose_word, garden_word : {s4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = torch.dot(rose_word, has_word)\n",
    "print(f\"Sim b/w rose_word, has_word : {s1}\")\n",
    "s2 = torch.dot(rose_word, beautiful_word)\n",
    "print(f\"Sim b/w rose_word, beautiful_word : {s2}\")\n",
    "s3 = torch.dot(rose_word, rose_word)\n",
    "print(f\"Sim b/w rose_word, rose_word : {s3}\")\n",
    "s4 = torch.dot(rose_word, garden_word)\n",
    "print(f\"Sim b/w rose_word, garden_word : {s4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load pre-trained Word2Vec model\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Sentence\n",
    "sentence = \"The car made a quick left turn and sped along the road.\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "tokens = word_tokenize(sentence.lower())\n",
    "\n",
    "# Get word embeddings for each word in the sentence\n",
    "word_embeddings = [word2vec_model[word] for word in tokens if word in word2vec_model]\n",
    "\n",
    "# Combine embeddings (e.g., average)\n",
    "import numpy as np\n",
    "sentence_embedding = np.mean(word_embeddings, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = \"rose has a beutiful rose garden\"\n",
    "import torch.nn.functional as F\n",
    "## Lets assign the words with word embeddings\n",
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89],\n",
    "     [0.55, 0.87, 0.66],\n",
    "     [0.57, 0.85, 0.64],\n",
    "     [0.22,0.58, 0.33],\n",
    "     [0.43, 0.15, 0.89],\n",
    "     [0.05, 0.80, 0.55]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = inputs.shape[1]\n",
    "d_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Query, Key, values weight matrices\n",
    "W_q = torch.rand(d_in, d_out, dtype = torch.float32, requires_grad=False)\n",
    "W_k = torch.rand(d_in, d_out, dtype = torch.float32, requires_grad=False)\n",
    "W_v = torch.rand(d_in, d_out, dtype = torch.float32, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the attention scores\n",
    "Q = inputs@W_q\n",
    "K = inputs@W_k\n",
    "V = inputs@W_v\n",
    "attn_scores = Q@K.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores\n",
    "\n",
    "# [[0.8089, 1.6977, 1.6636, 1.0353, 0.8089, 1.4218],<----- rose\n",
    "# [1.1166, 2.3618, 2.3143, 1.4418, 1.1166, 1.9798],\n",
    "# [1.1020, 2.3304, 2.2836, 1.4226, 1.1020, 1.9535],\n",
    "# [0.6146, 1.3032, 1.2770, 0.7958, 0.6146, 1.0928],\n",
    "# [0.8089, 1.6977, 1.6636, 1.0353, 0.8089, 1.4218],<----- rose\n",
    "# [0.7968, 1.6927, 1.6587, 1.0339, 0.7968, 1.4196]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_matrix = attn_scores/d_in**0.5\n",
    "attention_matrix  = F.softmax(attention_matrix, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vectors = attention_matrix@V\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Function to create positional encoding\n",
    "def get_positional_encoding(seq_len, d_model):\n",
    "    positional_encoding = torch.zeros(seq_len, d_model)\n",
    "    for pos in range(seq_len):\n",
    "        print(pos)\n",
    "        for i in range(0, d_model, 2):\n",
    "            positional_encoding[pos, i] = math.sin(pos / (10000 ** (i / d_model)))\n",
    "            print(\"sin\")\n",
    "            if i + 1 < d_model:\n",
    "                positional_encoding[pos, i + 1] = math.cos(pos / (10000 ** (i / d_model)))\n",
    "                print(\"cos\")\n",
    "    return positional_encoding\n",
    "\n",
    "# Sentence: \"rose has a beautiful rose garden\"\n",
    "# Using the same initial embedding for both occurrences of \"rose\"\n",
    "inputs = torch.tensor(\n",
    "    [\n",
    "        [0.56, 0.72, 0.89],  # rose (first occurrence)\n",
    "        [0.45, 0.65, 0.55],  # has\n",
    "        [0.31, 0.77, 0.22],  # a\n",
    "        [0.12, 0.85, 0.33],  # beautiful\n",
    "        [0.56, 0.72, 0.89],  # rose (second occurrence) - same embedding\n",
    "        [0.05, 0.80, 0.55]   # garden\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Dimension of the input embeddings (d_model)\n",
    "d_model = inputs.shape[1]\n",
    "\n",
    "# Create positional encoding\n",
    "seq_len = inputs.size(0)\n",
    "positional_encoding = get_positional_encoding(seq_len, d_model)\n",
    "\n",
    "# Add positional encoding to the input embeddings\n",
    "inputs += positional_encoding\n",
    "\n",
    "# Initialize weight matrices for query, key, and value transformations\n",
    "d_k = d_model  # Dimension for query and key (same as input embeddings)\n",
    "d_v = 2        # Output size for value embeddings (reduced dimension for simplicity)\n",
    "\n",
    "# Random weight matrices for Queries, Keys, and Values\n",
    "W_q = torch.rand(d_model, d_k)  # Query weight matrix\n",
    "W_k = torch.rand(d_model, d_k)  # Key weight matrix\n",
    "W_v = torch.rand(d_model, d_v)  # Value weight matrix\n",
    "\n",
    "# Step 1: Calculate Queries (Q), Keys (K), and Values (V)\n",
    "Q = inputs @ W_q  # Queries: shape (6, 3) @ (3, 3) = (6, 3)\n",
    "K = inputs @ W_k  # Keys: shape (6, 3) @ (3, 3) = (6, 3)\n",
    "V = inputs @ W_v  # Values: shape (6, 3) @ (3, 2) = (6, 2)\n",
    "\n",
    "# Step 2: Calculate attention scores (QK^T / sqrt(d_k))\n",
    "attn_scores = Q @ K.T  # shape (6, 3) @ (3, 6) = (6, 6)\n",
    "attn_scores /= d_k ** 0.5  # Scale by sqrt(d_k)\n",
    "\n",
    "# Step 3: Apply softmax to get attention weights\n",
    "attn_weights = F.softmax(attn_scores, dim=-1)  # shape (6, 6)\n",
    "\n",
    "# Step 4: Get context vectors by multiplying attention weights with Values (V)\n",
    "context_vectors = attn_weights @ V  # shape (6, 6) @ (6, 2) = (6, 2)\n",
    "\n",
    "# Print the attention weights and final context vectors\n",
    "print(\"Attention weights:\\n\", attn_weights)\n",
    "print(\"Context vectors (after self-attention):\\n\", context_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [\n",
    "        [],  # rose (first occurrence)\n",
    "        [],  # has\n",
    "        [0.31, 0.77, 0.22],  # a\n",
    "        [0.12, 0.85, 0.33],  # beautiful\n",
    "        [0.56, 0.72, 0.89],  # rose (second occurrence) - same embedding\n",
    "        [0.05, 0.80, 0.55]   # garden\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89],\n",
    "     [0.55, 0.87, 0.66],\n",
    "     [0.57, 0.85, 0.64],\n",
    "     [0.22,0.58, 0.33],\n",
    "     [0.77, 0.25, 0.10],\n",
    "     [0.05, 0.80, 0.55]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = inputs.shape[1]\n",
    "d_out = inputs.shape[1]\n",
    "torch.manual_seed(13)\n",
    "W_q = torch.rand(d_in, d_out, dtype = torch.float32)\n",
    "W_k = torch.rand(d_in, d_out, dtype = torch.float32)\n",
    "W_v = torch.rand(d_in, d_out, dtype = torch.float32)\n",
    "\n",
    "Q = inputs@W_q # Query vector\n",
    "K = inputs@W_k # Key vector\n",
    "V = inputs@W_v # Value vector\n",
    "\n",
    "### Calculate attention scores\n",
    "\n",
    "attn_scores = torch.softmax((Q@K.t())/(inputs.shape[0]**0.5), dim =1)\n",
    "\n",
    "context_vectors = attn_scores@V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1431, 0.2080, 0.2055, 0.1450, 0.1305, 0.1678],\n",
       "        [0.1423, 0.2112, 0.2087, 0.1425, 0.1296, 0.1657],\n",
       "        [0.1426, 0.2107, 0.2082, 0.1428, 0.1300, 0.1657],\n",
       "        [0.1546, 0.1889, 0.1877, 0.1545, 0.1476, 0.1666],\n",
       "        [0.1541, 0.1898, 0.1886, 0.1540, 0.1466, 0.1668],\n",
       "        [0.1512, 0.1950, 0.1935, 0.1513, 0.1425, 0.1665]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q@K.t()/inputs.shape[0]**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Self attention class\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "class SelfAttention_V1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W_q = nn.Parameter(torch.rand(d_in, d_out, dtype = torch.float32))\n",
    "        self.W_k = nn.Parameter(torch.rand(d_in, d_out, dtype = torch.float32))\n",
    "        self.W_v = nn.Parameter(torch.rand(d_in, d_out, dtype = torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x@self.W_k\n",
    "        query = x@self.W_q\n",
    "        values = x@self.W_v\n",
    "\n",
    "        attn_scores = torch.softmax((query@keys.T)/(keys.shape[1]**0.5), dim =1)\n",
    "\n",
    "        context_vectors = attn_scores@values\n",
    "\n",
    "        return context_vectors\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3751, 0.8610],\n",
      "        [1.4201, 0.8892],\n",
      "        [1.4198, 0.8890],\n",
      "        [1.3533, 0.8476],\n",
      "        [1.3746, 0.8606],\n",
      "        [1.3620, 0.8532]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89],\n",
    "     [0.55, 0.87, 0.66],\n",
    "     [0.57, 0.85, 0.64],\n",
    "     [0.22,0.58, 0.33],\n",
    "     [0.77, 0.25, 0.10],\n",
    "     [0.05, 0.80, 0.55]]\n",
    ")\n",
    "d_in = inputs.shape[1]\n",
    "d_out = inputs.shape[1]\n",
    "sa_v1 = SelfAttention_V1(d_in, 2)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
